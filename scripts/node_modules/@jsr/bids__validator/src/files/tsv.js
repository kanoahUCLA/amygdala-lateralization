/*
 * TSV
 * Module for parsing TSV
 */ import { TextLineStream } from "@jsr/std__streams";
import { ColumnsMap } from "../types/columns.js";
import { filememoizeAsync } from "../utils/memoize.js";
import { createUTF8Stream } from "./streams.js";
import { openStream } from "./access.js";
async function loadColumns(reader, headers, maxRows, startRow = 0) {
  // Initialize columns in array for construction efficiency
  const initialCapacity = maxRows >= 0 ? maxRows : 1000;
  const columns = headers.map(()=>new Array(initialCapacity));
  maxRows = maxRows >= 0 ? maxRows : Infinity;
  let rowIndex = 0 // Keep in scope after loop
  ;
  for(; rowIndex < maxRows; rowIndex++){
    const { done, value } = await reader.read();
    if (done) break;
    // Expect a newline at the end of the file, but otherwise error on empty lines
    if (!value) {
      const nextRow = await reader.read();
      if (nextRow.done) break;
      throw {
        code: 'TSV_EMPTY_LINE',
        line: rowIndex + startRow + 1
      };
    }
    const values = value.split('\t');
    if (values.length !== headers.length) {
      throw {
        code: 'TSV_EQUAL_ROWS',
        line: rowIndex + startRow + 1
      };
    }
    columns.forEach((column, columnIndex)=>{
      // Double array size if we exceed the current capacity
      if (rowIndex >= column.length) {
        column.length = column.length * 2;
      }
      column[rowIndex] = values[columnIndex];
    });
  }
  // Construct map, truncating columns to number of rows read
  return new ColumnsMap(headers.map((header, index)=>[
      header,
      columns[index].slice(0, rowIndex)
    ]));
}
export async function loadTSVGZ(file, headers, maxRows = -1) {
  const stream = await openStream(file);
  const reader = stream.pipeThrough(new DecompressionStream('gzip')).pipeThrough(createUTF8Stream({
    fatal: true
  })).pipeThrough(new TextLineStream()).getReader();
  try {
    return await loadColumns(reader, headers, maxRows);
  } catch (e) {
    // Cancel the reader if we interrupted the read
    // Cancelling for I/O errors will just re-trigger the error
    if (e.code) {
      await reader.cancel();
      throw e;
    }
    throw {
      code: 'INVALID_GZIP',
      location: file.path
    };
  }
}
async function _loadTSV(file, maxRows = -1) {
  const stream = await openStream(file);
  const reader = stream.pipeThrough(createUTF8Stream({
    fatal: true
  })).pipeThrough(new TextLineStream()).getReader();
  try {
    const headerRow = await reader.read();
    const headers = headerRow.done || !headerRow.value ? [] : headerRow.value.split('\t');
    if (new Set(headers).size !== headers.length) {
      throw {
        code: 'TSV_COLUMN_HEADER_DUPLICATE',
        location: file.path,
        issueMessage: headers.join(', ')
      };
    }
    return await loadColumns(reader, headers, maxRows, 1);
  } finally{
    await reader.cancel();
  }
}
export const loadTSV = filememoizeAsync(_loadTSV);
//# sourceMappingURL=tsv.js.map